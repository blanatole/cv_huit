{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏗️ Training U-Net với EfficientNet Backbone\n",
    "\n",
    "Notebook này thực hiện training model **U-Net với EfficientNet backbone** cho bài toán phân đoạn khối u da:\n",
    "\n",
    "## 🎯 Model: U-Net + EfficientNet\n",
    "- **Architecture**: U-Net với EfficientNet-B0 encoder\n",
    "- **Backbone**: EfficientNet-B0 (pre-trained trên ImageNet)\n",
    "- **Parameters**: ~5.3M\n",
    "- **Ưu điểm**: Cân bằng tốt giữa hiệu suất và tốc độ, efficient architecture\n",
    "- **Learning Rate Scheduler**: ReduceLROnPlateau (adaptive)\n",
    "\n",
    "## 📊 Training Configuration:\n",
    "- **Epochs**: 25\n",
    "- **Learning Rate**: 1e-4\n",
    "- **Batch Size**: 8\n",
    "- **Optimizer**: Adam với weight decay 1e-4\n",
    "- **Loss Function**: Combined Loss (BCE + Dice)\n",
    "- **Metrics**: Dice Coefficient, Jaccard Index (IoU)\n",
    "- **Scheduler**: ReduceLROnPlateau (patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import thư viện và setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt các thư viện cần thiết\n",
    "!pip install segmentation-models-pytorch timm torch torchvision\n",
    "!pip install albumentations opencv-python-headless\n",
    "!pip install matplotlib seaborn scikit-learn pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransforms\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Segmentation models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msegmentation_models_pytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmp\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Timm for backbone\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtimm\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'segmentation_models_pytorch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Segmentation models\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Timm for backbone\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import jaccard_score, f1_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Tạo thư mục models nếu chưa có\n",
    "os.makedirs('models', exist_ok=True)\n",
    "print(\"✅ Setup hoàn tất!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset và Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None, target_size=(512, 512)):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # Lấy danh sách file images\n",
    "        self.image_files = sorted([f for f in os.listdir(images_dir) \n",
    "                                 if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        \n",
    "        print(f\"Found {len(self.image_files)} images in {images_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find corresponding mask\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        possible_mask_names = [\n",
    "            f\"{base_name}_segmentation.png\",\n",
    "            f\"{base_name}_mask.png\",\n",
    "            f\"{base_name}.png\"\n",
    "        ]\n",
    "        \n",
    "        mask = None\n",
    "        for mask_name in possible_mask_names:\n",
    "            mask_path = os.path.join(self.masks_dir, mask_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                break\n",
    "        \n",
    "        if mask is None:\n",
    "            # Create dummy mask if not found\n",
    "            mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        \n",
    "        # Resize\n",
    "        image = cv2.resize(image, self.target_size)\n",
    "        mask = cv2.resize(mask, self.target_size)\n",
    "        \n",
    "        # Convert mask to binary\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "        \n",
    "        # Apply augmentations\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        # Convert to tensor if not already\n",
    "        if not isinstance(image, torch.Tensor):\n",
    "            image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0\n",
    "        \n",
    "        if not isinstance(mask, torch.Tensor):\n",
    "            mask = torch.from_numpy(mask).float().unsqueeze(0)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Define augmentations\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "print(\"✅ Dataset class và augmentations đã được định nghĩa!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ISICDataset(\n",
    "    images_dir='data/train/images',\n",
    "    masks_dir='data/train/ground_truth',\n",
    "    transform=train_transform,\n",
    "    target_size=(512, 512)\n",
    ")\n",
    "\n",
    "val_dataset = ISICDataset(\n",
    "    images_dir='data/val/images',\n",
    "    masks_dir='data/val/ground_truth',\n",
    "    transform=val_transform,\n",
    "    target_size=(512, 512)\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"📊 Dataset Summary:\")\n",
    "print(f\"   - Training samples: {len(train_dataset)}\")\n",
    "print(f\"   - Validation samples: {len(val_dataset)}\")\n",
    "print(f\"   - Batch size: {batch_size}\")\n",
    "print(f\"   - Training batches: {len(train_loader)}\")\n",
    "print(f\"   - Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. U-Net EfficientNet Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetEfficientNet(nn.Module):\n",
    "    def __init__(self, backbone_name=\"efficientnet-b0\", num_classes=1, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Sử dụng segmentation_models_pytorch để tạo U-Net với EfficientNet backbone\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=backbone_name,\n",
    "            encoder_weights=\"imagenet\" if pretrained else None,\n",
    "            in_channels=3,\n",
    "            classes=num_classes,\n",
    "            activation=None  # We'll apply sigmoid manually\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ U-Net EfficientNet model created:\")\n",
    "        print(f\"   - Backbone: {backbone_name}\")\n",
    "        print(f\"   - Pre-trained: {pretrained}\")\n",
    "        print(f\"   - Number of classes: {num_classes}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through U-Net\n",
    "        logits = self.model(x)\n",
    "        \n",
    "        # Apply sigmoid for binary segmentation\n",
    "        return torch.sigmoid(logits)\n",
    "\n",
    "# Initialize model\n",
    "print(\"🏗️ Initializing U-Net EfficientNet model...\")\n",
    "model = UNetEfficientNet(\n",
    "    backbone_name=\"efficientnet-b0\",\n",
    "    num_classes=1,\n",
    "    pretrained=True\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"📊 Model Statistics:\")\n",
    "print(f\"   - Total parameters: {total_params:,}\")\n",
    "print(f\"   - Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   - Model size: ~{total_params/1e6:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Functions và Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.dice = DiceLoss()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        return self.alpha * self.bce(pred, target) + (1 - self.alpha) * self.dice(pred, target)\n",
    "\n",
    "def calculate_dice_batch(pred, target, threshold=0.5):\n",
    "    \"\"\"Calculate Dice coefficient for a batch\"\"\"\n",
    "    pred_binary = (pred > threshold).float()\n",
    "    target_binary = target.float()\n",
    "    \n",
    "    intersection = (pred_binary * target_binary).sum()\n",
    "    dice = (2. * intersection) / (pred_binary.sum() + target_binary.sum() + 1e-6)\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "def calculate_jaccard_batch(pred, target):\n",
    "    \"\"\"Calculate Jaccard Index (IoU) for a batch\"\"\"\n",
    "    intersection = (pred & target).float().sum()\n",
    "    union = (pred | target).float().sum()\n",
    "    \n",
    "    jaccard = intersection / (union + 1e-6)\n",
    "    return jaccard.item()\n",
    "\n",
    "print(\"✅ Loss functions và metrics đã được định nghĩa!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Function với ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unet_efficientnet(model, train_loader, val_loader, num_epochs=25, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Training function for U-Net EfficientNet with ReduceLROnPlateau scheduler\n",
    "    \"\"\"\n",
    "    # Loss function and optimizer\n",
    "    criterion = CombinedLoss(alpha=0.5)  # Combination of BCE and Dice loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    \n",
    "    # ReduceLROnPlateau scheduler (adaptive)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', patience=3, factor=0.5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_losses': [],\n",
    "        'val_losses': [],\n",
    "        'train_dice': [],\n",
    "        'val_dice': [],\n",
    "        'train_jaccard': [],\n",
    "        'val_jaccard': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    print(f\"🚀 Bắt đầu training U-Net EfficientNet...\")\n",
    "    print(f\"📊 Configuration:\")\n",
    "    print(f\"   - Epochs: {num_epochs}\")\n",
    "    print(f\"   - Learning Rate: {lr}\")\n",
    "    print(f\"   - Scheduler: ReduceLROnPlateau (patience=3, factor=0.5)\")\n",
    "    print(f\"   - Loss: Combined (BCE + Dice)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_dice = 0.0\n",
    "        train_jaccard = 0.0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Training')\n",
    "        for batch_idx, (images, masks) in enumerate(train_pbar):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            with torch.no_grad():\n",
    "                pred_masks = outputs > 0.5\n",
    "                dice = calculate_dice_batch(outputs, masks)\n",
    "                jaccard = calculate_jaccard_batch(pred_masks, masks.bool())\n",
    "                train_dice += dice\n",
    "                train_jaccard += jaccard\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}', \n",
    "                'Dice': f'{dice:.3f}', \n",
    "                'Jaccard': f'{jaccard:.3f}'\n",
    "            })\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        val_jaccard = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} - Validation')\n",
    "            for images, masks in val_pbar:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                pred_masks = outputs > 0.5\n",
    "                dice = calculate_dice_batch(outputs, masks)\n",
    "                jaccard = calculate_jaccard_batch(pred_masks, masks.bool())\n",
    "                val_dice += dice\n",
    "                val_jaccard += jaccard\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}', \n",
    "                    'Dice': f'{dice:.3f}', \n",
    "                    'Jaccard': f'{jaccard:.3f}'\n",
    "                })\n",
    "        \n",
    "        # Calculate averages\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        train_dice /= len(train_loader)\n",
    "        val_dice /= len(val_loader)\n",
    "        train_jaccard /= len(train_loader)\n",
    "        val_jaccard /= len(val_loader)\n",
    "        \n",
    "        # Update learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_loss)  # ReduceLROnPlateau uses validation loss\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Store history\n",
    "        history['train_losses'].append(train_loss)\n",
    "        history['val_losses'].append(val_loss)\n",
    "        history['train_dice'].append(train_dice)\n",
    "        history['val_dice'].append(val_dice)\n",
    "        history['train_jaccard'].append(train_jaccard)\n",
    "        history['val_jaccard'].append(val_jaccard)\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        if abs(current_lr - new_lr) > 1e-8:\n",
    "            print(f\"  Learning rate changed: {current_lr:.6f} -> {new_lr:.6f}\")\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}, Train Jaccard: {train_jaccard:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}, Val Jaccard: {val_jaccard:.4f}\")\n",
    "        print(f\"  LR: {current_lr:.6f}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'models/unet_efficientnet_model_best.pth')\n",
    "            print(f\"New best validation loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"✅ Training function đã được định nghĩa!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bắt đầu Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the U-Net EfficientNet model\n",
    "print(\"🚀 Bắt đầu training U-Net EfficientNet...\")\n",
    "print(\"⏰ Thời gian dự kiến: ~1-2 giờ (tùy thuộc vào GPU)\")\n",
    "print()\n",
    "\n",
    "unet_efficientnet_history = train_unet_efficientnet(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=25,\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), 'models/unet_efficientnet_model_final.pth')\n",
    "print(\"\\n🎉 U-Net EfficientNet training hoàn thành!\")\n",
    "print(\"💾 Model đã được lưu:\")\n",
    "print(\"   - models/unet_efficientnet_model_best.pth (best validation loss)\")\n",
    "print(\"   - models/unet_efficientnet_model_final.pth (final epoch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization và Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_name=\"U-Net EfficientNet\"):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['train_losses'], label='Train Loss', color='blue')\n",
    "    axes[0, 0].plot(history['val_losses'], label='Val Loss', color='red')\n",
    "    axes[0, 0].set_title(f'{model_name} - Training & Validation Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Dice Coefficient\n",
    "    axes[0, 1].plot(history['train_dice'], label='Train Dice', color='blue')\n",
    "    axes[0, 1].plot(history['val_dice'], label='Val Dice', color='red')\n",
    "    axes[0, 1].set_title(f'{model_name} - Dice Coefficient')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Dice Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Jaccard Index\n",
    "    axes[1, 0].plot(history['train_jaccard'], label='Train Jaccard', color='blue')\n",
    "    axes[1, 0].plot(history['val_jaccard'], label='Val Jaccard', color='red')\n",
    "    axes[1, 0].set_title(f'{model_name} - Jaccard Index (IoU)')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Jaccard Score')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[1, 1].plot(history['learning_rates'], label='Learning Rate', color='green')\n",
    "    axes[1, 1].set_title(f'{model_name} - Learning Rate Schedule')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Learning Rate')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "print(\"📊 Hiển thị training history:\")\n",
    "plot_training_history(unet_efficientnet_history, \"U-Net EfficientNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_samples(model, val_loader, num_samples=6):\n",
    "    \"\"\"Evaluate model on sample images\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get some samples\n",
    "    samples = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(val_loader):\n",
    "            if i >= num_samples // val_loader.batch_size + 1:\n",
    "                break\n",
    "                \n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            for j in range(min(images.shape[0], num_samples - len(samples))):\n",
    "                # Denormalize image for visualization\n",
    "                img = images[j].cpu()\n",
    "                mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "                std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "                img = img * std + mean\n",
    "                img = torch.clamp(img, 0, 1)\n",
    "                \n",
    "                samples.append({\n",
    "                    'image': img.permute(1, 2, 0).numpy(),\n",
    "                    'true_mask': masks[j, 0].cpu().numpy(),\n",
    "                    'pred_mask': outputs[j, 0].cpu().numpy(),\n",
    "                    'pred_binary': (outputs[j, 0] > 0.5).cpu().numpy().astype(np.uint8)\n",
    "                })\n",
    "                \n",
    "                if len(samples) >= num_samples:\n",
    "                    break\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(4, len(samples), figsize=(20, 16))\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        # Original image\n",
    "        axes[0, i].imshow(sample['image'])\n",
    "        axes[0, i].set_title(f'Original {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # True mask\n",
    "        axes[1, i].imshow(sample['true_mask'], cmap='gray')\n",
    "        axes[1, i].set_title(f'True Mask {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Predicted mask (probability)\n",
    "        axes[2, i].imshow(sample['pred_mask'], cmap='hot', vmin=0, vmax=1)\n",
    "        axes[2, i].set_title(f'Pred Prob {i+1}')\n",
    "        axes[2, i].axis('off')\n",
    "        \n",
    "        # Predicted mask (binary)\n",
    "        axes[3, i].imshow(sample['pred_binary'], cmap='gray')\n",
    "        axes[3, i].set_title(f'Pred Binary {i+1}')\n",
    "        axes[3, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('U-Net EfficientNet - Prediction Results', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate model on samples\n",
    "print(\"🔍 Đánh giá model trên validation samples:\")\n",
    "evaluate_model_on_samples(model, val_loader, num_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final results\n",
    "print(\"🎯 U-NET EFFICIENTNET TRAINING RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📊 Final Metrics (Last Epoch):\")\n",
    "print(f\"   - Training Loss: {unet_efficientnet_history['train_losses'][-1]:.4f}\")\n",
    "print(f\"   - Validation Loss: {unet_efficientnet_history['val_losses'][-1]:.4f}\")\n",
    "print(f\"   - Training Dice: {unet_efficientnet_history['train_dice'][-1]:.4f}\")\n",
    "print(f\"   - Validation Dice: {unet_efficientnet_history['val_dice'][-1]:.4f}\")\n",
    "print(f\"   - Training Jaccard: {unet_efficientnet_history['train_jaccard'][-1]:.4f}\")\n",
    "print(f\"   - Validation Jaccard: {unet_efficientnet_history['val_jaccard'][-1]:.4f}\")\n",
    "\n",
    "print(f\"\\n🏆 Best Metrics:\")\n",
    "best_val_dice_idx = np.argmax(unet_efficientnet_history['val_dice'])\n",
    "best_val_jaccard_idx = np.argmax(unet_efficientnet_history['val_jaccard'])\n",
    "print(f\"   - Best Validation Dice: {max(unet_efficientnet_history['val_dice']):.4f} (Epoch {best_val_dice_idx + 1})\")\n",
    "print(f\"   - Best Validation Jaccard: {max(unet_efficientnet_history['val_jaccard']):.4f} (Epoch {best_val_jaccard_idx + 1})\")\n",
    "\n",
    "print(f\"\\n💾 Saved Models:\")\n",
    "print(f\"   - models/unet_efficientnet_model_best.pth\")\n",
    "print(f\"   - models/unet_efficientnet_model_final.pth\")\n",
    "\n",
    "print(f\"\\n📈 Model Performance:\")\n",
    "final_dice = unet_efficientnet_history['val_dice'][-1]\n",
    "final_jaccard = unet_efficientnet_history['val_jaccard'][-1]\n",
    "\n",
    "if final_dice > 0.85:\n",
    "    print(f\"   ✅ Excellent performance! Dice > 0.85\")\n",
    "elif final_dice > 0.80:\n",
    "    print(f\"   ✅ Good performance! Dice > 0.80\")\n",
    "elif final_dice > 0.75:\n",
    "    print(f\"   ⚠️  Acceptable performance. Dice > 0.75\")\n",
    "else:\n",
    "    print(f\"   ❌ Performance needs improvement. Dice < 0.75\")\n",
    "\n",
    "print(f\"\\n🚀 Next Steps:\")\n",
    "print(f\"   1. Run 04_train_unet_vit.ipynb to train U-Net ViT\")\n",
    "print(f\"   2. Run 05_train_deeplabv3_resnet.ipynb to train DeepLabV3+ ResNet\")\n",
    "print(f\"   3. Compare all models' performance\")\n",
    "\n",
    "print(\"\\n✅ U-Net EfficientNet training completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
