# PhÃ¢n Ä‘oáº¡n khá»‘i u trong áº£nh y táº¿ sá»­ dá»¥ng Pre-trained Models

Dá»± Ã¡n nÃ y thá»±c hiá»‡n bÃ i toÃ¡n phÃ¢n Ä‘oáº¡n khá»‘i u da (skin lesion segmentation) sá»­ dá»¥ng cÃ¡c pre-trained models tá»« Hugging Face Transformers vÃ  Timm trÃªn dataset ISIC vá»›i cÃ¡c cáº£i tiáº¿n hiá»‡n Ä‘áº¡i.

## ğŸš€ Cáº­p nháº­t má»›i: Sá»­ dá»¥ng Google Drive API

Project Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ sá»­ dá»¥ng **Google Drive API** thay vÃ¬ `gdown` Ä‘á»ƒ táº£i dá»¯ liá»‡u, mang láº¡i nhiá»u Æ°u Ä‘iá»ƒm:

### âœ… Æ¯u Ä‘iá»ƒm cá»§a Google Drive API:
- **Báº£o máº­t cao hÆ¡n**: Sá»­ dá»¥ng Service Account thay vÃ¬ public link
- **á»”n Ä‘á»‹nh hÆ¡n**: KhÃ´ng bá»‹ giá»›i háº¡n tá»‘c Ä‘á»™ nhÆ° `gdown`
- **Kiá»ƒm soÃ¡t quyá»n truy cáº­p**: CÃ³ thá»ƒ quáº£n lÃ½ ai Ä‘Æ°á»£c phÃ©p táº£i dá»¯ liá»‡u
- **Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh**: Thanh tiáº¿n trÃ¬nh chi tiáº¿t khi táº£i file lá»›n
- **Xá»­ lÃ½ lá»—i tá»‘t hÆ¡n**: ThÃ´ng bÃ¡o lá»—i rÃµ rÃ ng vÃ  hÆ°á»›ng dáº«n kháº¯c phá»¥c

### ğŸ“ Cáº¥u trÃºc file má»›i:
- `data_downloader.py`: Module chÃ­nh Ä‘á»ƒ táº£i dá»¯ liá»‡u tá»« Google Drive API
- `download.py`: Script Ä‘Æ¡n giáº£n Ä‘á»ƒ táº£i dataset
- `test_notebook_cell.py`: Script test Ä‘á»ƒ kiá»ƒm tra notebook cell
- `service_account.json`: File credentials cho Google Drive API (cáº§n táº¡o)

## ğŸ¯ Má»¥c tiÃªu

- PhÃ¢n Ä‘oáº¡n chÃ­nh xÃ¡c vÃ¹ng khá»‘i u da trong áº£nh y táº¿
- So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c pre-trained models khÃ¡c nhau
- ÄÃ¡nh giÃ¡ káº¿t quáº£ báº±ng **Dice Coefficient** vÃ  **Jaccard Index** (IoU)
- Tá»‘i Æ°u hÃ³a training vá»›i **Learning Rate Scheduling** hiá»‡n Ä‘áº¡i
- Tá»• chá»©c models má»™t cÃ¡ch chuyÃªn nghiá»‡p trong folder `models/`

## ğŸ“Š Dataset

**ISIC (International Skin Imaging Collaboration)**
- Training images: Khoáº£ng 2000+ áº£nh
- Validation images: Khoáº£ng 150+ áº£nh  
- Test images: Khoáº£ng 600+ áº£nh
- Format: JPG (images) vÃ  PNG (masks)

Cáº¥u trÃºc thÆ° má»¥c:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/          # áº¢nh training
â”‚   â””â”€â”€ ground_truth/    # Mask training
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/          # áº¢nh validation
â”‚   â””â”€â”€ ground_truth/    # Mask validation
â””â”€â”€ test/
    â”œâ”€â”€ images/          # áº¢nh test
    â””â”€â”€ ground_truth/    # Mask test
```

## ğŸš€ Models Ä‘Æ°á»£c sá»­ dá»¥ng

### 1. SegFormer (Hugging Face)
- **Model**: `nvidia/segformer-b0-finetuned-ade-512-512`
- **Æ¯u Ä‘iá»ƒm**: Hiá»‡u suáº¥t cao, Ã­t tham sá»‘ (3.7M)
- **Kiáº¿n trÃºc**: Transformer-based segmentation
- **Learning Rate Scheduler**: Cosine Annealing (phÃ¹ há»£p vá»›i transformer)
- **Saved as**: `models/segformer_model.pth`

### 2. Vision Transformer (ViT) Segmentation
- **Model**: `google/vit-base-patch16-224` + Custom segmentation head
- **Æ¯u Ä‘iá»ƒm**: Attention mechanism máº¡nh máº½, hiá»‡u suáº¥t cao trÃªn medical images
- **Tham sá»‘**: ~86M
- **Kiáº¿n trÃºc**: Pure transformer vá»›i patch-based processing
- **Learning Rate Scheduler**: Cosine Annealing vá»›i warmup
- **Saved as**: `models/vit_segmentation_model.pth`

### 3. U-Net vá»›i EfficientNet Backbone (Timm)
- **Backbone**: EfficientNet-B0 (`efficientnet-b0`)
- **Æ¯u Ä‘iá»ƒm**: CÃ¢n báº±ng tá»‘t giá»¯a hiá»‡u suáº¥t vÃ  tá»‘c Ä‘á»™
- **Tham sá»‘**: ~5.3M
- **Learning Rate Scheduler**: ReduceLROnPlateau (adaptive)
- **Saved as**: `models/unet_efficientnet_model.pth`

### 4. U-Net vá»›i ViT Backbone (Timm)
- **Backbone**: Vision Transformer Base (`vit_base_patch16_224`)
- **Æ¯u Ä‘iá»ƒm**: Káº¿t há»£p Æ°u Ä‘iá»ƒm cá»§a ViT vÃ  U-Net architecture
- **Tham sá»‘**: ~90M
- **Learning Rate Scheduler**: Cosine Annealing vá»›i warmup
- **Saved as**: `models/unet_vit_model.pth`

### 5. DeepLabV3+ vá»›i ResNet Backbone (Timm)
- **Backbone**: ResNet-50
- **Æ¯u Ä‘iá»ƒm**: Robust, xá»­ lÃ½ tá»‘t multi-scale objects
- **Tham sá»‘**: ~39.6M
- **Learning Rate Scheduler**: StepLR (scheduled decay)
- **Saved as**: `models/deeplabv3_resnet_model.pth`

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Python packages:
```bash
# Core ML libraries
pip install transformers timm torch torchvision
pip install segmentation-models-pytorch accelerate datasets
pip install albumentations opencv-python-headless
pip install matplotlib seaborn scikit-learn pillow tqdm

# Google Drive API (má»›i)
pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2

# Hoáº·c cÃ i Ä‘áº·t táº¥t cáº£ tá»« requirements.txt
pip install -r requirements.txt
```

### ğŸ”‘ Setup Google Drive API:

#### BÆ°á»›c 1: Táº¡o Service Account
1. Truy cáº­p [Google Cloud Console](https://console.cloud.google.com/)
2. Táº¡o project má»›i hoáº·c chá»n project hiá»‡n cÃ³
3. Báº­t Google Drive API:
   - VÃ o **APIs & Services** > **Library**
   - TÃ¬m "Google Drive API" vÃ  báº­t nÃ³
4. Táº¡o Service Account:
   - VÃ o **APIs & Services** > **Credentials**
   - Click **Create Credentials** > **Service Account**
   - Äáº·t tÃªn vÃ  táº¡o service account
5. Táº¡o key cho Service Account:
   - Click vÃ o service account vá»«a táº¡o
   - VÃ o tab **Keys** > **Add Key** > **Create New Key**
   - Chá»n **JSON** vÃ  táº£i vá»
   - Äá»•i tÃªn file thÃ nh `service_account.json`

#### BÆ°á»›c 2: Chia sáº» Google Drive file
1. Má»Ÿ file Google Drive cáº§n táº£i (dataset)
2. Click **Share** (Chia sáº»)
3. ThÃªm email cá»§a service account (cÃ³ dáº¡ng `xxx@project-name.iam.gserviceaccount.com`)
4. Cáº¥p quyá»n **Viewer** hoáº·c **Editor**

#### BÆ°á»›c 3: Äáº·t file credentials
```bash
# Äáº·t file service_account.json vÃ o thÆ° má»¥c gá»‘c cá»§a project
mv ~/Downloads/service_account.json ./service_account.json
```

### Hardware:
- **GPU**: NVIDIA GPU vá»›i Ã­t nháº¥t 8GB VRAM (khuyáº¿n nghá»‹)
- **RAM**: Ãt nháº¥t 16GB
- **Storage**: Ãt nháº¥t 10GB cho dataset vÃ  models

## ğŸ”§ CÃ¡ch sá»­ dá»¥ng

### 1. Clone repository
```bash
git clone https://github.com/blanatole/CV_Master.git
cd CV_Master
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 3. Setup Google Drive API (báº¯t buá»™c)
LÃ m theo hÆ°á»›ng dáº«n á»Ÿ pháº§n **ğŸ”‘ Setup Google Drive API** á»Ÿ trÃªn Ä‘á»ƒ táº¡o `service_account.json`

## ğŸ“š **5 NOTEBOOKS Äá»˜C Láº¬P** - CÃ¡ch sá»­ dá»¥ng má»›i

Project Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh **5 notebooks nhá»** Ä‘á»ƒ dá»… dÃ ng quáº£n lÃ½ vÃ  cháº¡y tá»«ng pháº§n riÃªng biá»‡t:

### ğŸ“‹ **Danh sÃ¡ch Notebooks:**

#### 1. ğŸ“¥ `01_data_download.ipynb` - Táº£i vÃ  Chuáº©n bá»‹ Dá»¯ liá»‡u
**Má»¥c Ä‘Ã­ch**: Táº£i dataset ISIC tá»« Google Drive vÃ  chuáº©n bá»‹ dá»¯ liá»‡u cho training

**Ná»™i dung**:
- Táº£i dá»¯ liá»‡u tá»« Google Drive API
- Giáº£i nÃ©n vÃ  táº¡o cáº¥u trÃºc thÆ° má»¥c
- KhÃ¡m phÃ¡ vÃ  visualize dá»¯ liá»‡u
- PhÃ¢n tÃ­ch thá»‘ng kÃª dataset
- Táº¡o summary cho cÃ¡c notebook training

**Thá»i gian**: ~10-15 phÃºt
**YÃªu cáº§u**: File `service_account.json` cho Google Drive API

#### 2. ğŸ¤– `02_train_segformer.ipynb` - Training SegFormer
**Má»¥c Ä‘Ã­ch**: Train model SegFormer (Transformer-based segmentation)

**Cáº¥u hÃ¬nh**:
- **Model**: `nvidia/segformer-b0-finetuned-ade-512-512`
- **Parameters**: ~3.7M
- **Epochs**: 20
- **Learning Rate**: 5e-5
- **Scheduler**: Cosine Annealing
- **Æ¯u Ä‘iá»ƒm**: Hiá»‡u suáº¥t cao, Ã­t tham sá»‘

**Thá»i gian**: ~2-3 giá»
**Output**: `models/segformer_model_*.pth`

#### 3. ğŸ—ï¸ `03_train_unet_efficientnet.ipynb` - Training U-Net EfficientNet
**Má»¥c Ä‘Ã­ch**: Train U-Net vá»›i EfficientNet backbone

**Cáº¥u hÃ¬nh**:
- **Backbone**: EfficientNet-B0
- **Parameters**: ~5.3M
- **Epochs**: 25
- **Learning Rate**: 1e-4
- **Scheduler**: ReduceLROnPlateau (adaptive)
- **Æ¯u Ä‘iá»ƒm**: CÃ¢n báº±ng tá»‘t giá»¯a hiá»‡u suáº¥t vÃ  tá»‘c Ä‘á»™

**Thá»i gian**: ~1-2 giá»
**Output**: `models/unet_efficientnet_model_*.pth`

#### 4. ğŸ”¬ `04_train_unet_vit.ipynb` - Training U-Net ViT
**Má»¥c Ä‘Ã­ch**: Train U-Net vá»›i Vision Transformer backbone

**Cáº¥u hÃ¬nh**:
- **Backbone**: Vision Transformer Base
- **Parameters**: ~90M
- **Epochs**: 20
- **Learning Rate**: 1e-4
- **Scheduler**: Cosine Annealing vá»›i Warmup (5 epochs)
- **Æ¯u Ä‘iá»ƒm**: Attention mechanism máº¡nh máº½

**Thá»i gian**: ~2-3 giá»
**Output**: `models/unet_vit_model_*.pth`

#### 5. ğŸ¯ `05_train_deeplabv3_resnet.ipynb` - Training DeepLabV3+ ResNet
**Má»¥c Ä‘Ã­ch**: Train DeepLabV3+ vá»›i ResNet backbone

**Cáº¥u hÃ¬nh**:
- **Backbone**: ResNet-50
- **Parameters**: ~39.6M
- **Epochs**: 15
- **Learning Rate**: 1e-4
- **Scheduler**: StepLR (step_size=5, gamma=0.1)
- **Æ¯u Ä‘iá»ƒm**: Robust, xá»­ lÃ½ tá»‘t multi-scale objects

**Thá»i gian**: ~3-4 giá»
**Output**: `models/deeplabv3_resnet_model_*.pth`

### ğŸš€ **CÃ¡ch cháº¡y Notebooks:**

#### **BÆ°á»›c 1: Chuáº©n bá»‹ mÃ´i trÆ°á»ng**
```bash
# Clone repository
git clone <repository_url>
cd cv_huit

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

#### **BÆ°á»›c 2: Setup Google Drive API (cho notebook 1)**
1. Táº¡o Service Account trÃªn Google Cloud Console
2. Táº£i file credentials vÃ  Ä‘á»•i tÃªn thÃ nh `service_account.json`
3. Chia sáº» dataset vá»›i service account email

#### **BÆ°á»›c 3: Cháº¡y notebooks theo thá»© tá»±**

##### ğŸ“¥ **Báº¯t buá»™c**: Cháº¡y notebook 1 trÆ°á»›c
```bash
jupyter notebook 01_data_download.ipynb
```
- Cháº¡y táº¥t cáº£ cells tá»« trÃªn xuá»‘ng dÆ°á»›i
- Äáº£m báº£o dá»¯ liá»‡u Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng

##### ğŸ¤– **TÃ¹y chá»n**: Cháº¡y cÃ¡c notebook training (2-5)
Báº¡n cÃ³ thá»ƒ cháº¡y **báº¥t ká»³ notebook nÃ o** trong sá»‘ 4 notebook training:

```bash
# SegFormer (nháº¹ nháº¥t, nhanh nháº¥t)
jupyter notebook 02_train_segformer.ipynb

# U-Net EfficientNet (cÃ¢n báº±ng)
jupyter notebook 03_train_unet_efficientnet.ipynb

# U-Net ViT (hiá»‡u suáº¥t cao)
jupyter notebook 04_train_unet_vit.ipynb

# DeepLabV3+ ResNet (robust nháº¥t)
jupyter notebook 05_train_deeplabv3_resnet.ipynb
```

### ğŸ“Š **So sÃ¡nh Models**

| Model | Parameters | Training Time | Dice Score* | Jaccard Index* | Scheduler |
|-------|------------|---------------|-------------|----------------|-----------|
| SegFormer | 3.7M | 2-3h | ~0.90 | ~0.82 | Cosine Annealing |
| U-Net EfficientNet | 5.3M | 1-2h | ~0.89 | ~0.81 | ReduceLROnPlateau |
| U-Net ViT | 90M | 2-3h | ~0.90 | ~0.83 | Cosine + Warmup |
| DeepLabV3+ ResNet | 39.6M | 3-4h | ~0.89 | ~0.80 | StepLR |

*Káº¿t quáº£ dá»± kiáº¿n, cÃ³ thá»ƒ thay Ä‘á»•i tÃ¹y thuá»™c vÃ o dataset vÃ  hyperparameters

### ğŸ’¾ **Cáº¥u trÃºc Output**

Sau khi cháº¡y cÃ¡c notebooks, báº¡n sáº½ cÃ³:

```
cv_huit/
â”œâ”€â”€ data/                           # Dataset (tá»« notebook 1)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ models/                         # Trained models (tá»« notebooks 2-5)
â”‚   â”œâ”€â”€ segformer_model_best.pth
â”‚   â”œâ”€â”€ segformer_model_final.pth
â”‚   â”œâ”€â”€ unet_efficientnet_model_best.pth
â”‚   â”œâ”€â”€ unet_efficientnet_model_final.pth
â”‚   â”œâ”€â”€ unet_vit_model_best.pth
â”‚   â”œâ”€â”€ unet_vit_model_final.pth
â”‚   â”œâ”€â”€ deeplabv3_resnet_model_best.pth
â”‚   â””â”€â”€ deeplabv3_resnet_model_final.pth
â””â”€â”€ notebooks/
    â”œâ”€â”€ 01_data_download.ipynb
    â”œâ”€â”€ 02_train_segformer.ipynb
    â”œâ”€â”€ 03_train_unet_efficientnet.ipynb
    â”œâ”€â”€ 04_train_unet_vit.ipynb
    â””â”€â”€ 05_train_deeplabv3_resnet.ipynb
```

### ğŸ¯ **Lá»±a chá»n Model phÃ¹ há»£p**

#### ğŸš€ **Náº¿u báº¡n muá»‘n nhanh vÃ  hiá»‡u quáº£**:
â†’ Cháº¡y `02_train_segformer.ipynb` (SegFormer)
- Ãt tham sá»‘ nháº¥t (3.7M)
- Hiá»‡u suáº¥t cao
- Training nhanh

#### âš–ï¸ **Náº¿u báº¡n muá»‘n cÃ¢n báº±ng**:
â†’ Cháº¡y `03_train_unet_efficientnet.ipynb` (U-Net EfficientNet)
- CÃ¢n báº±ng tá»‘t giá»¯a hiá»‡u suáº¥t vÃ  tá»‘c Ä‘á»™
- Training nhanh nháº¥t (1-2h)

#### ğŸ¯ **Náº¿u báº¡n muá»‘n hiá»‡u suáº¥t cao nháº¥t**:
â†’ Cháº¡y `04_train_unet_vit.ipynb` (U-Net ViT)
- Attention mechanism máº¡nh máº½
- Hiá»‡u suáº¥t cao trÃªn medical images

#### ğŸ›¡ï¸ **Náº¿u báº¡n muá»‘n robust nháº¥t**:
â†’ Cháº¡y `05_train_deeplabv3_resnet.ipynb` (DeepLabV3+ ResNet)
- Xá»­ lÃ½ tá»‘t multi-scale objects
- ASPP module cho multi-scale features

### ğŸ”§ **Troubleshooting**

#### âŒ **Lá»—i Google Drive API**:
- Kiá»ƒm tra file `service_account.json`
- Äáº£m báº£o service account cÃ³ quyá»n truy cáº­p file
- Kiá»ƒm tra káº¿t ná»‘i internet

#### âŒ **Lá»—i giáº£i nÃ©n RAR** (phá»• biáº¿n nháº¥t):
```bash
# Cháº¡y script fix tá»± Ä‘á»™ng
python fix_extraction.py

# Hoáº·c cÃ i Ä‘áº·t thá»§ cÃ´ng
pip install rarfile

# Linux/Ubuntu
sudo apt install unrar

# macOS
brew install unrar

# Windows: Táº£i WinRAR hoáº·c 7-Zip
```

#### âŒ **Lá»—i GPU Memory**:
- Giáº£m batch_size tá»« 8 xuá»‘ng 4 hoáº·c 2
- Sá»­ dá»¥ng CPU náº¿u cáº§n: `device = 'cpu'`

#### âŒ **Lá»—i Dependencies**:
```bash
pip install --upgrade torch torchvision
pip install --upgrade transformers timm
pip install segmentation-models-pytorch
```

### ğŸ“ **Notes**

- **Notebook 1** lÃ  **báº¯t buá»™c** pháº£i cháº¡y trÆ°á»›c
- **Notebooks 2-5** cÃ³ thá»ƒ cháº¡y **Ä‘á»™c láº­p** vá»›i nhau
- Má»—i notebook tá»± Ä‘á»™ng lÆ°u model tá»‘t nháº¥t vÃ  model cuá»‘i cÃ¹ng
- Táº¥t cáº£ notebooks Ä‘á»u cÃ³ visualization vÃ  evaluation
- CÃ³ thá»ƒ dá»«ng vÃ  tiáº¿p tá»¥c training báº±ng cÃ¡ch load model Ä‘Ã£ lÆ°u

### ğŸ‰ **Káº¿t luáº­n**

Project Ä‘Ã£ Ä‘Æ°á»£c tá»• chá»©c thÃ nh **5 notebooks Ä‘á»™c láº­p** Ä‘á»ƒ:
- âœ… Dá»… dÃ ng quáº£n lÃ½ vÃ  debug
- âœ… CÃ³ thá»ƒ cháº¡y tá»«ng model riÃªng biá»‡t
- âœ… Tiáº¿t kiá»‡m thá»i gian khi chá»‰ cáº§n train 1 model
- âœ… Dá»… dÃ ng so sÃ¡nh vÃ  thá»­ nghiá»‡m
- âœ… CÃ³ thá»ƒ cháº¡y song song trÃªn nhiá»u GPU/mÃ¡y khÃ¡c nhau

**Happy Training! ğŸš€**

## ğŸ“ˆ Metrics Ä‘Ã¡nh giÃ¡ chÃ­nh

### ğŸ¯ **Dice Coefficient** (Primary Metric)
```
Dice = 2 * |A âˆ© B| / (|A| + |B|)
```
- **Ã nghÄ©a**: Äo Ä‘á»™ tÆ°Æ¡ng tá»± giá»¯a prediction vÃ  ground truth
- **Pháº¡m vi**: 0-1 (cÃ ng cao cÃ ng tá»‘t)
- **Æ¯u Ä‘iá»ƒm**: Robust vá»›i class imbalance

### ğŸ¯ **Jaccard Index (IoU)** (Secondary Metric)
```
Jaccard = |A âˆ© B| / |A âˆª B|
```
- **Ã nghÄ©a**: Äo Ä‘á»™ chá»“ng láº¥p giá»¯a prediction vÃ  ground truth
- **Pháº¡m vi**: 0-1 (cÃ ng cao cÃ ng tá»‘t)
- **Quan há»‡**: Jaccard = Dice / (2 - Dice)

### ğŸ“Š **Combined Loss Function**
```
Combined Loss = Î± * BCE Loss + (1-Î±) * Dice Loss
```
- **Î± = 0.5**: CÃ¢n báº±ng giá»¯a pixel-wise accuracy vÃ  shape similarity
- **Lá»£i Ã­ch**: Tá»‘i Æ°u hÃ³a cáº£ Ä‘á»™ chÃ­nh xÃ¡c pixel vÃ  hÃ¬nh dáº¡ng tá»•ng thá»ƒ

### ğŸ“‹ **Additional Metrics**
- **Sensitivity (Recall)**: `TP / (TP + FN)` - Tá»· lá»‡ phÃ¡t hiá»‡n Ä‘Ãºng khá»‘i u
- **Specificity**: `TN / (TN + FP)` - Tá»· lá»‡ loáº¡i bá» Ä‘Ãºng vÃ¹ng khÃ´ng pháº£i khá»‘i u

## ğŸ¨ Data Augmentation

Sá»­ dá»¥ng Albumentations vá»›i cÃ¡c transforms:
- **Geometric**: HorizontalFlip, VerticalFlip, RandomRotate90, ShiftScaleRotate
- **Color**: RandomBrightnessContrast, HueSaturationValue
- **Normalization**: ImageNet standards (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
- **Resize**: 512x512 pixels cho táº¥t cáº£ models

## ğŸ”§ Cáº£i tiáº¿n ká»¹ thuáº­t

### ğŸ“Š **Enhanced Metrics System**
- **Primary**: Dice Coefficient (robust vá»›i class imbalance)
- **Secondary**: Jaccard Index (IoU) cho comparison
- **Real-time tracking**: Train/Val metrics trong má»—i epoch
- **Comprehensive logging**: Loss, Dice, Jaccard, Learning Rate

### ğŸ“ˆ **Advanced Learning Rate Scheduling**
- **Model-specific schedulers**: PhÃ¹ há»£p vá»›i tá»«ng architecture
- **Automatic LR change detection**: Hiá»ƒn thá»‹ khi LR thay Ä‘á»•i
- **Visualization**: Plot LR schedules Ä‘á»ƒ so sÃ¡nh

### ğŸ’¾ **Professional Model Management**
```
models/
â”œâ”€â”€ segformer_model.pth          # SegFormer weights
â”œâ”€â”€ unet_efficientnet_model.pth  # U-Net weights
â””â”€â”€ deeplabv3_resnet_model.pth   # DeepLabV3+ weights
```

### ğŸ¯ **Enhanced Loss Function**
- **Combined Loss**: Tá»‘i Æ°u cáº£ pixel accuracy vÃ  shape similarity
- **Adaptive weighting**: Î±=0.5 cÃ¢n báº±ng BCE vÃ  Dice Loss
- **Gradient stability**: Smooth training convergence

## ğŸ” Káº¿t quáº£ mong Ä‘á»£i

| Model | Jaccard Index | Dice Coefficient | Parameters | LR Scheduler |
|-------|---------------|------------------|------------|--------------|
| SegFormer | ~0.82 | ~0.90 | 3.7M | Cosine Annealing |
| ViT Segmentation | ~0.84 | ~0.91 | 86M | Cosine + Warmup |
| U-Net (EfficientNet) | ~0.81 | ~0.89 | 5.3M | ReduceLROnPlateau |
| U-Net (ViT) | ~0.83 | ~0.90 | 90M | Cosine + Warmup |
| DeepLabV3+ (ResNet) | ~0.80 | ~0.89 | 39.6M | StepLR |

### ğŸ¯ **Performance Highlights:**
- **SegFormer**: Tá»‘t nháº¥t vá» efficiency (Ã­t tham sá»‘ nháº¥t)
- **U-Net**: CÃ¢n báº±ng tá»‘t giá»¯a performance vÃ  complexity
- **DeepLabV3+**: Robust nháº¥t vá»›i multi-scale features

*LÆ°u Ã½: Káº¿t quáº£ cÃ³ thá»ƒ thay Ä‘á»•i tÃ¹y thuá»™c vÃ o dataset vÃ  hyperparameters*

## ğŸ“ Cáº¥u trÃºc Notebooks

### ğŸ“¥ **Notebook 1: Data Download**
1. **Import thÆ° viá»‡n**: Google Drive API, visualization tools
2. **Google Drive Setup**: XÃ¡c thá»±c vÃ  káº¿t ná»‘i API
3. **Download Dataset**: Táº£i ISIC dataset vá»›i progress bar
4. **Data Exploration**: PhÃ¢n tÃ­ch cáº¥u trÃºc, visualize samples
5. **Statistics**: Thá»‘ng kÃª kÃ­ch thÆ°á»›c, phÃ¢n bá»‘ mask
6. **Summary**: Chuáº©n bá»‹ thÃ´ng tin cho training notebooks

### ğŸ¤– **Notebook 2: SegFormer Training**
1. **Setup**: Import transformers, segmentation libraries
2. **Dataset**: ISIC dataset vá»›i augmentation
3. **Model**: SegFormer tá»« Hugging Face
4. **Training**: Cosine Annealing scheduler, 20 epochs
5. **Evaluation**: Dice & Jaccard metrics, visualization
6. **Results**: Performance summary vÃ  model saving

### ğŸ—ï¸ **Notebook 3: U-Net EfficientNet Training**
1. **Setup**: Segmentation models pytorch, timm
2. **Dataset**: CÃ¹ng dataset vá»›i augmentation khÃ¡c nhau
3. **Model**: U-Net vá»›i EfficientNet-B0 backbone
4. **Training**: ReduceLROnPlateau scheduler, 25 epochs
5. **Evaluation**: Comprehensive metrics tracking
6. **Results**: Comparison vá»›i SegFormer

### ğŸ”¬ **Notebook 4: U-Net ViT Training**
1. **Setup**: Vision Transformer libraries, einops
2. **Dataset**: Optimized cho ViT input requirements
3. **Model**: U-Net vá»›i ViT backbone (hoáº·c ResNet fallback)
4. **Training**: Cosine Annealing vá»›i Warmup, 20 epochs
5. **Evaluation**: Advanced metrics vÃ  attention visualization
6. **Results**: High-performance model analysis

### ğŸ¯ **Notebook 5: DeepLabV3+ ResNet Training**
1. **Setup**: Multi-scale segmentation setup
2. **Dataset**: Same preprocessing pipeline
3. **Model**: DeepLabV3+ vá»›i ResNet-50, ASPP module
4. **Training**: StepLR scheduler, 15 epochs
5. **Evaluation**: Multi-scale performance analysis
6. **Results**: Robust model comparison vÃ  final summary

### ğŸ“Š **Tá»•ng káº¿t táº¥t cáº£ Notebooks**
- **Notebook 1**: Báº¯t buá»™c cháº¡y trÆ°á»›c (data preparation)
- **Notebooks 2-5**: Äá»™c láº­p, cÃ³ thá»ƒ cháº¡y báº¥t ká»³ thá»© tá»± nÃ o
- **Má»—i notebook**: Complete pipeline tá»« setup Ä‘áº¿n evaluation
- **Output**: Trained models trong folder `models/`
- **Visualization**: Training curves, predictions, comparisons

## ğŸš¨ LÆ°u Ã½ quan trá»ng

### Preprocessing:
- Resize áº£nh vá» 512x512 pixels
- Normalize theo ImageNet standards
- Binary threshold cho masks (>127 = 1, â‰¤127 = 0)

### Training:
- **Batch size**: 8 (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh theo GPU memory)
- **Learning rates**:
  - SegFormer: 5e-5 (lower for pre-trained transformer)
  - U-Net & DeepLabV3+: 1e-4
- **Optimizer**: Adam vá»›i weight decay 1e-4
- **Learning Rate Schedulers**:
  - **SegFormer**: Cosine Annealing (T_max=epochs, eta_min=lr*0.01)
  - **U-Net**: ReduceLROnPlateau (patience=3, factor=0.5)
  - **DeepLabV3+**: StepLR (step_size=epochs//3, gamma=0.1)
- **Loss Function**: Combined Loss (Î±=0.5) = BCE Loss + Dice Loss

### Validation:
- Sá»­ dá»¥ng separate validation set
- **Metrics tracking**: Train/Val Loss, Dice, Jaccard, Learning Rate
- **Model saving**: Táº¥t cáº£ models lÆ°u trong folder `models/`
- **Real-time monitoring**: Progress bars vá»›i metrics display

## ğŸ”® HÆ°á»›ng phÃ¡t triá»ƒn

### ğŸš€ **ÄÃ£ thá»±c hiá»‡n**:
- âœ… **Dice Coefficient & Jaccard Index** lÃ m metrics chÃ­nh
- âœ… **Learning Rate Scheduling** vá»›i 4 loáº¡i scheduler
- âœ… **Model Organization** trong folder `models/`
- âœ… **Enhanced Training Monitoring** vá»›i comprehensive metrics
- âœ… **Combined Loss Function** (BCE + Dice)

### ğŸ¯ **Káº¿ hoáº¡ch tiáº¿p theo**:
1. **Advanced Augmentation**: MixUp, CutMix, Mosaic
2. **Ensemble Methods**: Káº¿t há»£p predictions tá»« nhiá»u models
3. **Post-processing**: CRF, Watershed segmentation
4. **Multi-scale Training**: Train vá»›i nhiá»u resolutions
5. **Transfer Learning**: Fine-tune tá»« medical datasets khÃ¡c
6. **3D Segmentation**: Má»Ÿ rá»™ng cho volumetric data
7. **Model Optimization**: Pruning, Quantization, ONNX export
8. **Advanced Schedulers**: Warm-up, Polynomial decay

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [SegFormer Paper](https://arxiv.org/abs/2105.15203)
- [U-Net Paper](https://arxiv.org/abs/1505.04597)
- [DeepLabV3+ Paper](https://arxiv.org/abs/1802.02611)
- [ISIC Dataset](https://www.isic-archive.com/)
- [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)

## ğŸ¤ ÄÃ³ng gÃ³p

Má»i Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n! Vui lÃ²ng:
1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push vÃ  táº¡o Pull Request

## ğŸ“„ License

MIT License - xem file LICENSE Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

---

**LÆ°u Ã½**: ÄÃ¢y lÃ  project nghiÃªn cá»©u/há»c táº­p. KhÃ´ng sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch cháº©n Ä‘oÃ¡n y táº¿ thá»±c táº¿ mÃ  khÃ´ng cÃ³ sá»± giÃ¡m sÃ¡t cá»§a chuyÃªn gia y táº¿.
